[{
    "title": "Tidy Tuesday",
    "date": "",
    "description": "",
    "body": "\r\r\rFirst #TidyTuesday contribution for the year, still have a lot to catch up on clearly. I made a leaflet map from a blog post on https://t.co/wTAS19lPLv . Stuck at sharing the interactive html file for now. Code: https://t.co/2inpMWZfuB pic.twitter.com/e6SIl02Z8M\r— Professional Griefer (@PipeFunction) January 30, 2020\r\r\r\r\rPerfect timing for @dataandme's tweet…I decided to use {reactable} for this week's #TidyTuesday challenge. Showing average bird rating against number of votes. Still stuck at embedding the bird images though, to be continued… #rstats Code: https://t.co/FlFyoZKSa8 pic.twitter.com/Dsg86QBwqM\r— Professional Griefer (@PipeFunction) November 20, 2019\r\r\r\r\rMy contribution to this week's #TidyTuesday Grouped movies by quarter of the year they were released, Q4 movies have a slightly higher rating. Budgets don't always guarantee viewer success…Also, I just learnt I haven't watched Psychedelia yet #rstats #datavisualization pic.twitter.com/MT5NgkttW1\r— Professional Griefer (@PipeFunction) October 23, 2019\r\r\r\r\rTried out a Sankey plot for this week's #TidyTuesday data… Distribution of gender across age groups, body weight, and equipment used for Squat-Bench-Deadlift events. Code: https://t.co/6HLl7z6wzp #rstats #dataviz pic.twitter.com/5dcSGYHZ1H\r— Professional Griefer (@PipeFunction) October 9, 2019\r\r\r\r\rTried out a spaghetti plot for this weeks #TidyTuesday , reducing the unit_type to my own based on a few common features… Quick one, is it that there are very few accessible (they also started in the 50s-60s) parks with water bodies or guys just don't visit them? pic.twitter.com/yTmsplg41R\r— Professional Griefer (@PipeFunction) September 17, 2019\r\r\r\r\rFirst of many contributions to #TidyTuesday. The US and USSR were responsible for over 80% of explosions. Random fact; After rejecting the CTB treaty in, Pakistan tests six nuclear weapons, 1998 in response to India’s tests. code:https://t.co/nRM78MBSc1 #dataviz #rstats #ggplot2 pic.twitter.com/ZiXUzf7fZn\r— Professional Griefer (@PipeFunction) August 20, 2019\r\r\r\r\rAn update based on @CedScherer 's suggestion. Using the maximum value actually shows the true trend in percentage change while solving the overlaps issue. Mean skews the data hence not recommended…this plot here a better representation. #TidyTuesday #rstats #DataVisualization pic.twitter.com/Nk4VqXG8TB\r— Professional Griefer (@PipeFunction) September 6, 2019\r\r\r\r\rMoore's Law: Focused on Intel CPUs,% change in the avg no. of transistors yearly shows the exponential growth trend. However, the % change has been reducing over recent yrs. “It's the nature of exponential functions, they eventually hit a wall”- Moore (2005) #TidyTuesday #rstats pic.twitter.com/LngIYw9GtX\r— Professional Griefer (@PipeFunction) September 5, 2019\r\r\r\r\rHighlighting top 1000 nukes by yield, Bravo yielded the most megatons:15 followed by Yankee: 13.5 mt , Romeo:11 mt , Mike:10.4 mt , Handley:10 mt . All were US's , mostly deployed in Bikini…apart from Hanley which was UK's #rstats #TidyTuesday #dataviz pic.twitter.com/c9KnQGaUiH\r— Professional Griefer (@PipeFunction) August 21, 2019\r\r\r\r\r",
    "ref": "/project/tidy-tuesday/"
  },{
    "title": "Handy Shiny Apps",
    "date": "",
    "description": "",
    "body": "\r\rMotivation\rThis project contains links to my developed shiny apps you might find helpful…For every new interesting idea I have I’ll build an app. Some might be basic shiny, others might be complex shiny, depending on how important I think they are. Let me know what you think,suggestions for improvements and new apps are welcome.\n1. Live time progress A live time visualizing app with a stop watch for board games hosted in ShinyApp.io\n\r",
    "ref": "/project/shiny-apps/"
  },{
    "title": "Markdown Syntax Guide",
    "date": "",
    "description": "Sample article showcasing basic Markdown syntax and formatting for HTML elements.",
    "body": "This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\n Tables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    Inline  Markdown  In  Table     italics bold strikethrough  code    Code Blocks Code block with backticks \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Item  First Sub-item Second Sub-item    Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n  The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015. \u0026#x21a9;\u0026#xfe0e;\n  ",
    "ref": "/blog/markdown-syntax/"
  },{
    "title": "Rich Content",
    "date": "",
    "description": "A brief description of Hugo Shortcodes",
    "body": "Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\n Instagram Simple Shortcode .__h_instagram.card { font-family: -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; font-size: 14px; border: 1px solid rgb(219, 219, 219); padding: 0; margin-top: 30px; } .__h_instagram.card .card-header, .__h_instagram.card .card-body { padding: 10px 10px 10px; } .__h_instagram.card img { width: 100%; height: auto; }  koloot.design   View More on Instagram    YouTube Privacy Enhanced Shortcode    Twitter Simple Shortcode .twitter-tweet { font: 14px/1.45 -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; border-left: 4px solid #2b7bb9; padding-left: 1.5em; color: #555; } .twitter-tweet a { color: #2b7bb9; text-decoration: none; } blockquote.twitter-tweet a:hover, blockquote.twitter-tweet a:focus { text-decoration: underline; }  “In addition to being more logical, asymmetry has the advantage that its complete appearance is far more optically effective than symmetry.”\n— Jan Tschichold pic.twitter.com/gcv7SrhvJb\n\u0026mdash; Graphic Design History (@DesignReviewed) January 17, 2019  Vimeo Simple Shortcode  .__h_video { position: relative; padding-bottom: 56.23%; height: 0; overflow: hidden; width: 100%; background: #000; } .__h_video img { width: 100%; height: auto; color: #000; } .__h_video .play { height: 72px; width: 72px; left: 50%; top: 50%; margin-left: -36px; margin-top: -36px; position: absolute; cursor: pointer; }  ",
    "ref": "/blog/rich-content/"
  },{
    "title": "Placeholder Text",
    "date": "",
    "description": "Lorem Ipsum Dolor Si Amet",
    "body": "Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\n Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude  Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\n Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et  Vagus elidunt \nThe Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n",
    "ref": "/blog/placeholder-text/"
  },{
    "title": "Emoji Support",
    "date": "",
    "description": "Guide to emoji usage in Hugo",
    "body": "Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site’s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\n N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n.emoji { font-family: Apple Color Emoji,Segoe UI Emoji,NotoColorEmoji,Segoe UI Symbol,Android Emoji,EmojiSymbols; }",
    "ref": "/blog/emoji-support/"
  },{
    "title": "About",
    "date": "",
    "description": "Hugo, the world’s fastest framework for building websites",
    "body": "Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\n https://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n",
    "ref": "/about/"
  },{
    "title": "Digital Nudging",
    "date": "",
    "description": "Influencing online User decisions on Twitter through nudge units-A hackathon experience.",
    "body": "Introduction: Here\u0026rsquo;s a fun fact; An average human being (probably an adult) makes close to 30,000 conscious decisions every day. This isn\u0026rsquo;t entirely true though, in fact, I just made that number up. I could be right because if you think about it, how many decisions would you say you make on a day to day basis? Depending on who you are the above obviously varies widely and you know best. We all make n decisions every day- what to do, eat, buy or hit. The real question however is, do our daily choices solely depend on our consciousness? Are there any other factors at hand that influence our decision making process? Are all these factors, if any, always straight forward choices or do we sometimes get \u0026ldquo;nudged\u0026rdquo; into these choices we make?\nNudge theory basically states that; by understanding how people think and what drives their decisions, we can use those factors to steer them into making decisions differently, through positive reinforcement. Research has shown that, by presenting choices differently rather than in a legislative manner, people can be influenced into making specific desired choices. This theory is widely used in behavioral economics by presenting subtle nudge units intended to influence people\u0026rsquo;s thoughts about financial products. The theory was however initially more of a moral aspect meant to help people make better decisions in life and not as a tool for commercial gain. Over years of practice, different applications of the theory emerged.\nNow that we have a basic understanding of what nudge theory is about, we can explore an applicable example. This post mainly focuses on a short research project I happened to be part of, actually my first hackathon experience hosted by Safaricom PLC. Let\u0026rsquo;s dive in!\nThe Challenge This photo a team mate took at the hackathon contains a problem statement for the challenge:\n\r  Figure 1: The challenge\n  \rTools used: Our twitter data was fetched using R, I have done a post on setting up a twitter API to fetch twitter data here. R has several packages (such as \u0026ldquo;tweeteR\u0026rdquo; and \u0026ldquo;rtweet\u0026rdquo;) that one can use to stream data from twitter. Our data cleaning and pre-processing was mainly done in Python.\n Note: To keep this post concise, code for the workings has been minimized. The source code for this post can be found here, for anyone interested in trying out the same process. The code is well commented for easier understanding as well.\n 1.Fetching Data The team agreed on a few terms to query data on from twitter. For an unbiased range of topics, we settled on fetching tweets under trending topics and a few more from random words. We had tweets from or containing the following:\n #MenConference2019 “Here” #r_Stats “PWC” #Friday Feeling  # Install And Load Requried Packages\rinstall.packages(\u0026quot;twitteR\u0026quot;) #install package if not yet\rinstall.packages(\u0026quot;rtweet\u0026quot;) #install package if not yet\r#Load\rlibrary(\u0026quot;twitteR\u0026quot;)#------Extracts data from twitter\rlibrary(\u0026quot;rtweet\u0026quot;)#------Extracts data from twitter\r# create token named \u0026quot;twitter_token\u0026quot;\rtwitter_token \u0026lt;- create_token(\rapp = \u0026quot;BeyondRawData\u0026quot;, #The name of your twitter API app\rconsumer_key \u0026lt;- '4VfuSFDGSHF4566kssgmsgUUUDsff2',\rconsumer_secret \u0026lt;- 'ughjslkuynmwrtwtmwtoae',\raccess_token \u0026lt;- '6768w69w7twtw-BPHBOQT0pNdfhyFZzJ2jAsdffdRtgjgsfslZwpm',\raccess_secret \u0026lt;- '(9rHttKGJnaAVxMZHJhaxKbLt)9opodfggdgqBEHprqYnTpN5ysy')\r#Connect to twitter and fetch data\rrstats_tweets \u0026lt;- search_tweets(q = \u0026quot;#rstats\u0026quot;, n = 500)\rrstats_tweets2 \u0026lt;- search_tweets(q = \u0026quot;#rstats\u0026quot;, n = 5000) friday_Feeling \u0026lt;- search_tweets( q = \u0026quot;#FridayFeeling\u0026quot;, n = 500)\rHere_Tweet \u0026lt;- search_tweets( q = \u0026quot;here\u0026quot;, n = 500)\rPWc_Tweet \u0026lt;- search_tweets( q = \u0026quot;PWC\u0026quot;, n = 500)\r#Bind tweets to one data frame\rbind_Data\u0026lt;- rbind(rstats_tweets,rstats_tweets2,friday_Feeling,Here_Tweet,PWc_Tweet)\rbind_Data\u0026lt;- as.data.frame(bind_Data)\rA total of 7000 tweets were captured. The data frame had a total of 88 columns which we treated as variables for the research. However, not all variables were used in the research we therefore had to do some data cleaning. Here is a preview of the variables in our raw data.\n\u0026gt; bind_Data\u0026lt;- as.data.frame(bind_Data)\r\u0026gt; names(bind_Data)\r[1] \u0026quot;user_id\u0026quot; \u0026quot;status_id\u0026quot; \u0026quot;created_at\u0026quot; [4] \u0026quot;screen_name\u0026quot; \u0026quot;text\u0026quot; \u0026quot;source\u0026quot; [7] \u0026quot;display_text_width\u0026quot; \u0026quot;reply_to_status_id\u0026quot; \u0026quot;reply_to_user_id\u0026quot; [10] \u0026quot;reply_to_screen_name\u0026quot; \u0026quot;is_quote\u0026quot; \u0026quot;is_retweet\u0026quot; [13] \u0026quot;favorite_count\u0026quot; \u0026quot;retweet_count\u0026quot; \u0026quot;hashtags\u0026quot; [16] \u0026quot;symbols\u0026quot; \u0026quot;urls_url\u0026quot; \u0026quot;urls_t.co\u0026quot; [19] \u0026quot;urls_expanded_url\u0026quot; \u0026quot;media_url\u0026quot; \u0026quot;media_t.co\u0026quot; [22] \u0026quot;media_expanded_url\u0026quot; \u0026quot;media_type\u0026quot; \u0026quot;ext_media_url\u0026quot; [25] \u0026quot;ext_media_t.co\u0026quot; \u0026quot;ext_media_expanded_url\u0026quot; \u0026quot;ext_media_type\u0026quot; [28] \u0026quot;mentions_user_id\u0026quot; \u0026quot;mentions_screen_name\u0026quot; \u0026quot;lang\u0026quot; [31] \u0026quot;quoted_status_id\u0026quot; \u0026quot;quoted_text\u0026quot; \u0026quot;quoted_created_at\u0026quot; [34] \u0026quot;quoted_source\u0026quot; \u0026quot;quoted_favorite_count\u0026quot; \u0026quot;quoted_retweet_count\u0026quot; [37] \u0026quot;quoted_user_id\u0026quot; \u0026quot;quoted_screen_name\u0026quot; \u0026quot;quoted_name\u0026quot; [40] \u0026quot;quoted_followers_count\u0026quot; \u0026quot;quoted_friends_count\u0026quot; \u0026quot;quoted_statuses_count\u0026quot; [43] \u0026quot;quoted_location\u0026quot; \u0026quot;quoted_description\u0026quot; \u0026quot;quoted_verified\u0026quot; [46] \u0026quot;retweet_status_id\u0026quot; \u0026quot;retweet_text\u0026quot; \u0026quot;retweet_created_at\u0026quot; [49] \u0026quot;retweet_source\u0026quot; \u0026quot;retweet_favorite_count\u0026quot; \u0026quot;retweet_retweet_count\u0026quot; [52] \u0026quot;retweet_user_id\u0026quot; \u0026quot;retweet_screen_name\u0026quot; \u0026quot;retweet_name\u0026quot; [55] \u0026quot;retweet_followers_count\u0026quot; \u0026quot;retweet_friends_count\u0026quot; \u0026quot;retweet_statuses_count\u0026quot; [58] \u0026quot;retweet_location\u0026quot; \u0026quot;retweet_description\u0026quot; \u0026quot;retweet_verified\u0026quot; [61] \u0026quot;place_url\u0026quot; \u0026quot;place_name\u0026quot; \u0026quot;place_full_name\u0026quot; [64] \u0026quot;place_type\u0026quot; \u0026quot;country\u0026quot; \u0026quot;country_code\u0026quot; [67] \u0026quot;geo_coords\u0026quot; \u0026quot;coords_coords\u0026quot; \u0026quot;bbox_coords\u0026quot; [70] \u0026quot;status_url\u0026quot; \u0026quot;name\u0026quot; \u0026quot;location\u0026quot; [73] \u0026quot;description\u0026quot; \u0026quot;url\u0026quot; \u0026quot;protected\u0026quot; [76] \u0026quot;followers_count\u0026quot; \u0026quot;friends_count\u0026quot; \u0026quot;listed_count\u0026quot; [79] \u0026quot;statuses_count\u0026quot; \u0026quot;favourites_count\u0026quot; \u0026quot;account_created_at\u0026quot; [82] \u0026quot;verified\u0026quot; \u0026quot;profile_url\u0026quot; \u0026quot;profile_expanded_url\u0026quot; [85] \u0026quot;account_lang\u0026quot; \u0026quot;profile_banner_url\u0026quot; \u0026quot;profile_background_url\u0026quot; [88] \u0026quot;profile_image_url\u0026quot; [1] \u0026quot;user_id\u0026quot; \u0026quot;status_id\u0026quot; \u0026quot;created_at\u0026quot; [4] \u0026quot;screen_name\u0026quot; \u0026quot;text\u0026quot; \u0026quot;source\u0026quot; [7] \u0026quot;display_text_width\u0026quot; \u0026quot;reply_to_status_id\u0026quot; \u0026quot;reply_to_user_id\u0026quot; [10] \u0026quot;reply_to_screen_name\u0026quot; \u0026quot;is_quote\u0026quot; \u0026quot;is_retweet\u0026quot; [13] \u0026quot;favorite_count\u0026quot; \u0026quot;retweet_count\u0026quot; \u0026quot;hashtags\u0026quot; [16] \u0026quot;symbols\u0026quot; \u0026quot;urls_url\u0026quot; \u0026quot;urls_t.co\u0026quot; [19] \u0026quot;urls_expanded_url\u0026quot; \u0026quot;media_url\u0026quot; \u0026quot;media_t.co\u0026quot; [22] \u0026quot;media_expanded_url\u0026quot; \u0026quot;media_type\u0026quot; \u0026quot;ext_media_url\u0026quot; [25] \u0026quot;ext_media_t.co\u0026quot; \u0026quot;ext_media_expanded_url\u0026quot; \u0026quot;ext_media_type\u0026quot; [28] \u0026quot;mentions_user_id\u0026quot; \u0026quot;mentions_screen_name\u0026quot; \u0026quot;lang\u0026quot; [31] \u0026quot;quoted_status_id\u0026quot; \u0026quot;quoted_text\u0026quot; \u0026quot;quoted_created_at\u0026quot; [34] \u0026quot;quoted_source\u0026quot; \u0026quot;quoted_favorite_count\u0026quot; \u0026quot;quoted_retweet_count\u0026quot; [37] \u0026quot;quoted_user_id\u0026quot; \u0026quot;quoted_screen_name\u0026quot; \u0026quot;quoted_name\u0026quot; [40] \u0026quot;quoted_followers_count\u0026quot; \u0026quot;quoted_friends_count\u0026quot; \u0026quot;quoted_statuses_count\u0026quot; [43] \u0026quot;quoted_location\u0026quot; \u0026quot;quoted_description\u0026quot; \u0026quot;quoted_verified\u0026quot; [46] \u0026quot;retweet_status_id\u0026quot; \u0026quot;retweet_text\u0026quot; \u0026quot;retweet_created_at\u0026quot; [49] \u0026quot;retweet_source\u0026quot; \u0026quot;retweet_favorite_count\u0026quot; \u0026quot;retweet_retweet_count\u0026quot; [52] \u0026quot;retweet_user_id\u0026quot; \u0026quot;retweet_screen_name\u0026quot; \u0026quot;retweet_name\u0026quot; [55] \u0026quot;retweet_followers_count\u0026quot; \u0026quot;retweet_friends_count\u0026quot; \u0026quot;retweet_statuses_count\u0026quot; [58] \u0026quot;retweet_location\u0026quot; \u0026quot;retweet_description\u0026quot; \u0026quot;retweet_verified\u0026quot; [61] \u0026quot;place_url\u0026quot; \u0026quot;place_name\u0026quot; \u0026quot;place_full_name\u0026quot; [64] \u0026quot;place_type\u0026quot; \u0026quot;country\u0026quot; \u0026quot;country_code\u0026quot; [67] \u0026quot;geo_coords\u0026quot; \u0026quot;coords_coords\u0026quot; \u0026quot;bbox_coords\u0026quot; [70] \u0026quot;status_url\u0026quot; \u0026quot;name\u0026quot; \u0026quot;location\u0026quot; [73] \u0026quot;description\u0026quot; \u0026quot;url\u0026quot; \u0026quot;protected\u0026quot; [76] \u0026quot;followers_count\u0026quot; \u0026quot;friends_count\u0026quot; \u0026quot;listed_count\u0026quot; [79] \u0026quot;statuses_count\u0026quot; \u0026quot;favourites_count\u0026quot; \u0026quot;account_created_at\u0026quot; [82] \u0026quot;verified\u0026quot; \u0026quot;profile_url\u0026quot; \u0026quot;profile_expanded_url\u0026quot; [85] \u0026quot;account_lang\u0026quot; \u0026quot;profile_banner_url\u0026quot; \u0026quot;profile_background_url\u0026quot; [88] \u0026quot;profile_image_url\u0026quot;  2.Data pre-processing. This stage involved cleaning up our data by removing the unwanted columns/variables. We decided to do with a select few variables we thought would be most appropriate for our case study. We chose the following seven variables:\n Text - This column contained the actual tweets text. Verified - whether or not the user is verified on twitter. Protected - Whether a user is or isn\u0026rsquo;t protected (Locked accounts). Location - Based on our challenge stated in the figure above, this variable was our most important variable. Rows with NULL values for location simply meant that the specific user DID NOT GEOTAG their tweet. Followers Count - Number of followers the user had. Retweet Verifie - Whether the tweet had been retweeted by a verified user or not. Source - Source of the tweet i.e \u0026ldquo;Android\u0026rdquo;, \u0026ldquo;web client\u0026rdquo; e.t.c  #Removing unusable variables--They apear as lists in the data\rbind_Data\u0026lt;-subset(bind_Data, select = -c(hashtags,symbols,\rurls_url,urls_t.co,\rurls_expanded_url,media_url,\rmedia_t.co,media_expanded_url,media_type,ext_media_url,\rext_media_t.co,ext_media_expanded_url,mentions_user_id,\rmentions_screen_name,geo_coords,coords_coords,bbox_coords))\r#selecting variables to use in analysis.\rselected_Variables\u0026lt;- subset(bind_Data, select = c(text, verified, protected, location, followers_count, retweet_verified, source))\rnames(selected_Variables)\r##Output \u0026gt; names(selected_Variables)\r[1] \u0026quot;text\u0026quot; \u0026quot;verified\u0026quot; \u0026quot;protected\u0026quot; \u0026quot;location\u0026quot; [5] \u0026quot;followers_count\u0026quot; \u0026quot;retweet_verified\u0026quot; \u0026quot;source\u0026quot; #write the data into a CSV file and load intopython for cleanup\rwrite.csv(selected_Variables,\u0026quot;Myvariables.csv\u0026quot;)#Write CSV to a working directory then clean up using python #To check your working directory, do:\rgetwd() #--For example, mine is [1] \u0026quot;J:/Personalprojects/SafComHackathon/Tweeter\u0026quot;\rCode for the data cleanup and variables setting that was done in Python can be found here.\n2.1 Re-importing Data in R and setting up for the Models After cleaning up the data, we imported it into R, the code chunk shows a preview of the top 4 rows of the input data.\n\u0026gt; #Data Prep\r\u0026gt; #Shuffle data\r\u0026gt; index.shuffle \u0026lt;- sample(1:nrow(data)) #Shuffle data index to randomize contents and remove bias\r\u0026gt; #Data\r\u0026gt; data\u0026lt;-read.csv(\u0026quot;Variables3.csv\u0026quot;, stringsAsFactors = TRUE) #read CSV data that had been cleade up in Python\r\u0026gt; data \u0026lt;- data[index.shuffle, ]\r\u0026gt; head(data, 4)\rX\r1074 1074\r1316 1316\r2636 2636\r2939 2939\rText\r1074 Want to know how to optimize hyper-parameters in Caret with cost-specific functions? #rstats #datascience https://t.co/cupvirSXU9\r1316 via @RichardEudes - Quick Guide to R and Statistical Programming https://t.co/GfyhLMgiuB #analytics, #datascience, #rstats, #statistics https://t.co/Cx3TGJTOoI\r2636 small #rstats trick: if you need to know if a *sorted* variable is equally spaced (e.g., if it's a contiguous sequence of ints, which was my use case) you can look at the characteristics of diff(x), e.g.\\n\\nsummary(diff(x))\\ntable(diff(x))\r2939 my #ggplot2 flipbook project is online! \u0026lt;U+0001F60E\u0026gt;\u0026lt;U+0001F913\u0026gt;\u0026lt;U+0001F913\u0026gt; Incrementally walks through plotting code (#MakeoverMonday, soon #TidyTuesday plots). Using #xaringan with reveal function; thanks, @statsgen @grrrck. #rstats. https://t.co/bBBzv0iZLw https://t.co/tFtD78IOHZ\rVerified Protected Location Followers VerifiedRetweet\r1074 FALSE FALSE Singapore 1570 FALSE\r1316 FALSE FALSE Paris, France 2151 NA\r2636 FALSE FALSE Pleasant Hill, CA 1207 NA\r2939 FALSE FALSE Sri Lanka 2623 FALSE\rCharacters\r1074 DS-retweet\r1316 IFTTT\r2636 Twitter Web Client\r2939 Twitter for Android\rText\r1074 Want to know how to optimize hyper-parameters in Caret with cost-specific functions? #rstats #datascience https://t.co/cupvirSXU9\r1316 via @RichardEudes - Quick Guide to R and Statistical Programming https://t.co/GfyhLMgiuB #analytics, #datascience, #rstats, #statistics https://t.co/Cx3TGJTOoI\r2636 small #rstats trick: if you need to know if a *sorted* variable is equally spaced (e.g., if it's a contiguous sequence of ints, which was my use case) you can look at the characteristics of diff(x), e.g.\\n\\nsummary(diff(x))\\ntable(diff(x))\r2939 my #ggplot2 flipbook project is online! \u0026lt;U+0001F60E\u0026gt;\u0026lt;U+0001F913\u0026gt;\u0026lt;U+0001F913\u0026gt; Incrementally walks through plotting code (#MakeoverMonday, soon #TidyTuesday plots). Using #xaringan with reveal function; thanks, @statsgen @grrrck. #rstats. https://t.co/bBBzv0iZLw https://t.co/tFtD78IOHZ\rVerified Protected Location Followers VerifiedRetweet\r1074 FALSE FALSE Singapore 1570 FALSE\r1316 FALSE FALSE Paris, France 2151 NA\r2636 FALSE FALSE Pleasant Hill, CA 1207 NA\r2939 FALSE FALSE Sri Lanka 2623 FALSE\rCharacters\r1074 DS-retweet\r1316 IFTTT\r2636 Twitter Web Client\r2939 Twitter for Android\rWe still had to do some data pre-processing for the models which includes checking for and removing NULL values if present. Below is a sample table of the final data set used in the analysis.\n#Clean Data\rlibrary(dplyr)\r# Drop variables\rclean_data\u0026lt;- data %\u0026gt;%\rmutate( Text= as.numeric(Text),VerifiedRetweet = as.numeric(VerifiedRetweet), Characters= as.numeric(Characters),\rVerified = as.numeric(Verified), Protected = as.numeric(Protected),Location = as.numeric(Location))%\u0026gt;% data.frame()\rclean_data$Location = ifelse(clean_data$Location \u0026lt; 2, \u0026quot;NON-TAGGED\u0026quot;, \u0026quot;TAGGED\u0026quot;) #set geotags to true or false clean_data$Followers = ifelse(clean_data$Followers \u0026lt; 500, 0, 1) # if number of followers is greater than 500 then TRUE\ris.na(clean_data$VerifiedRetweet) \u0026lt;- 1 #Remove NA values\rclean_data[is.na(clean_data[-1,])] = 1 #Convert NA values to 1\r#View(clean_data)\rhead(clean_data)\r#Output\r\u0026gt; head(clean_data)\rVerified Protected Location Followers VerifiedRetweet Characters\r1 0 0 TAGGED 1 1 55\r2 1 1 NON-TAGGED 1 1 80\r3 0 0 TAGGED 1 1 193\r4 0 0 TAGGED 1 0 188\r5 1 0 TAGGED 0 1 188\r6 0 0 NON-TAGGED 0 0 190\r\u0026gt;    Verified Protected Location Followers VerifiedRetweet Characters     NO NO TAGGED \u0026gt;500 YES 55   YES YES NON-TAGGED \u0026gt;500 YES 80   NO NO TAGGED \u0026gt;500 YES 193   NO NO TAGGED \u0026gt;500 NO 188   YES NO TAGGED 500\u0026lt; YES 188   NO NO NON-TAGGED 500\u0026lt; NO 190    From the table above, we can observe a new column \u0026ldquo;Characters\u0026rdquo;. This was an additional variable derived by counting the number of characters in the tweet text.\n3.Model Specifications Due to the nature of our problem,(we had several uncorrelated variables) we decided to do a classification analysis. This means we had to come up with a classifier model to regress n variables based on our dependent variable, the Location variable. The main challenge of classifier models is knowing what really goes on inside the models that leads to the final output. Even with higher levels of accuracy in some models, it is quite difficult o understand the paths of a given model. However, using Random forests and Decision Tree classifiers can give us a graphical representation of the criteria followed by the models to arrive at a given output. Another upper hand of decision tree models is that they require minimal data cleaning, less time consuming. Here is a detailed read on how decision trees work.\nCreating Train \u0026amp; Test Sets. For the training and test data sets, we randomly split our data set into two sates. Usually, the best practice is to train the model with with a larger proportion of the data set. We therefore took 80% for training and 20% for test purposes.\n#Train \u0026amp; Test sets\rcreate_train_test\u0026lt;- function(data, size = 0.8, train = TRUE) {\rn_row = nrow(data)\rtotal_row = size * n_row\rtrain_sample\u0026lt;- 1: total_row\rif (train == TRUE) {\rreturn (data[train_sample, ])\r} else {\rreturn (data[-train_sample, ])\r}\r}\rclean_data1 = subset(clean_data, select = -c(X,Protected) ) #remove unwanted variables\rdata_train \u0026lt;- create_train_test(clean_data1, 0.8, train = TRUE)\rdata_test \u0026lt;- create_train_test(clean_data1, 0.8, train = FALSE)\rdim(data_train) #Checkdimensions for train data\rdim(data_test) #Checkdimensions for test data\r\nModel Training. We trained our decision tree model to predict a class \u0026ldquo;location\u0026rdquo;. Whether a location is geotagged or not geotagged based on whether the user is verified, protected, has over 500 followers, is retweeted by another verified user and the number of characters in their tweet. Bellow is the visual output of the trained model.\n#install.packages(\u0026quot;rpart.plot\u0026quot;)\t-This is for decision trees.\r#Create and fit model\rlibrary(rpart)#load package\rlibrary(rpart.plot)#load package\rfit \u0026lt;- rpart(Location ~ ., data = data_train, method = 'class')\r# set.seed(27)\r# fit \u0026lt;- rpart(Location ~ .,\r# data = data_train,\r# method = \u0026quot;class\u0026quot;,\r# control = rpart.control(xval = 10, minbucket = 2, cp = 0), parms = list(split = \u0026quot;information\u0026quot;))\rrpart.plot(fit)\r\r  Figure 2: The Tree\n  \rWhen interpreting decision trees, you start at the root node. The root node is the one on top of the decision tree. Since what we want is those nodes with geotagged locations, it is safe to ignore the non-tagged nodes. Note that our highest entropy level was observed on one variable only, the number of characters in the tweet text. This might not always be the case with decision trees though, it is possible to have more than one factor. In such situations, it is best to run several decision trees to build a random forest and make a decision based on the most prevalent variables.\nFor our case, we only focus on what we found:\n  At the top node, we can see the overall probability of a user geotagging their tweets. 75 percent of the users in the training set geotagged their tweets. not\n  Our second node asks whether the number of characters are more than 134 and goes to depth 2 where we can observe the highest number of users tweeted more than 134 characters at 80 percent with an 80 percent probability of geotagging their tweets.\n  Node 3 checks if the number of characters in a tweet is less than 134. If yes, head to depth 3, where we can see that 20 percent of users had less than 134 characters with a 50 percent probability of geotagging their tweets.\n  Finally, looking at depth 4 which originates from the node that checks is number of characters is equal to or more than 122, we can see that 12 percent of users had tweets with character equal to or more than 124, with 88 percent probability of geotagging their tweets.\n  3.1 Model Testing and performance accuracy. With our model trained and outputs observed, we were able to run a test with our test subset. Here is our confusion matrix.\n#Predicting\rpredict_geotags \u0026lt;-predict(fit, data_test, type = 'class')\rtable_mat \u0026lt;- table(data_test$Location, predict_geotags)\r\u0026gt; table_mat\rpredict_geotags\rNON-TAGGED TAGGED\rNON-TAGGED 90 248\rTAGGED 2 1043\r#performance\raccuracy_Test \u0026lt;- sum(diag(table_mat)) / sum(table_mat)\rprint(paste('Accuracy for test is', accuracy_Test))\r[1] \u0026quot;Accuracy for test is 0.819233550253073\u0026quot;\rConfusion matrix predict_geotags\rNON-TAGGED TAGGED\rNON-TAGGED 90 248\rTAGGED 2 1043\r\nModel Accuracy \u0026gt; #performance\r\u0026gt; accuracy_Test \u0026lt;- sum(diag(table_mat)) / sum(table_mat)\r\u0026gt; print(paste('Accuracy for test is', accuracy_Test))\r[1] \u0026quot;Accuracy for test is 0.819233550253073\u0026quot;\rFrom the confusion matrix above, we can observe that the model had a true negative of 90 predictions. That is, 90 predictions were correctly predicted as not geotagged. A false positive of 248 predictions was observed where the model wrongly predicted 248 tweets were geotagged whereas in real sense they were not.\nFor the tagged tweets, we had a false negative of 2 predictions against a true positive of 1043 predictions. This means that our model was able to correctly predict 1043 geotagged tweets from the test data. The accuracy of the model turned out pretty good, at an 82 percent accuracy level. The theoretical formula for the accuracy is the proportion of true positives and the true negatives divided by the sum of the confusion matrix.\n\r$$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n\rFor a better accuracy level, the model\u0026rsquo;s hyper-parameters can be tweaked to improve performance. Another option is implementing a random forest test.\n4. Conclusion and Recommendation With our decision tree model, we were able to attain a high level of accuracy for a model that test whether users with tweets containing characters equal to or above 122 are likely to geotag their tweets. Our nudge in this case is the number of characters in a tweet and precisely, 124 or more. Our recommendation therefore would be to encourage users to tweet longer or engage them in trending topics that require one to write more, for example a TT like # MyLifeHistoryInANutshell\u0026hellip;-in the hope that a user will eventually geotag their tweet.\n Come to think of it, did twitter really increase the number of characters just for tweeps to tweet more and as they said, to get more people to join twitter? I have a theory, it was a NUDGE!\n References   Business balls official website\n  Thaler, R.H., Sunstein, C.R., and Balz, J.P. Choice Architecture. SSRN Electronic Journal (2010), 1–18; https://ssrn.com/abstract=1583509\n  Thaler, R.H. and Sunstein, C.R. Nudge: Improving Decisions About Health, Wealth, and Happiness. Yale University Press, New Haven, CT, and London, U.K., 2008.\n  \r\r",
    "ref": "/blog/digital-nudging/2019-02-17-digital-nudging/"
  },{
    "title": "Contact",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
